#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Dec 22 15:59:36 2021

@author: pkorus
"""

import os
import sys
import json
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
import seaborn as sns

from helpers import results as hr
from helpers import plotting

#%% Compare training-time vs post-training validation

# Optim
test_gallery = Dataset('data/vs_mv_pairs/mv_test_population_interspeech_1000u_10s.csv')
test_gallery.precomputed_embeddings(sv)



# MV Test
test_gallery = Dataset('data/vs_mv_pairs/mv_test_population_interspeech_1000u_10s.csv')
test_gallery.precomputed_embeddings(sv)

#embeddings = [0.0, 0.0, 0.0, 0.039325573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...] max 0.46728554

sims_temp, imps_temp, gnds_temp = sv.test_error_rates(embeddings, test_gallery, policy='avg', level='far1', playback=0)

# %%

df = hr.results_df('data/results/plain_normed/vggvox_v000_pgd_spec_f', None)
# df = df[df['steps'] == 10]

print(df.to_string())

# %%

sns.lineplot(x='pesq', y='far1-mv', marker='o', hue='step_size', data=df,
               palette=sns.color_palette(None, len(df)))
# plt.gca().set_xscale('log')
plt.gca().set_title('vggvox, spec, normed, f')

# %%

df_p = hr.results_df('data/results/plain_normed/vggvox_v000_pgd_wave_f')
df_n = hr.results_df('data/results/play_normed/vggvox_v000_pgd_wave_f')

d_metric = 'pesq'

plt.plot(df_p[d_metric].values, df_p['far1-mv'].values, 'o-', label='pgd')
plt.plot(df_n[d_metric].values, df_n['far1-mv'].values, 'o-', label='normed')
plt.legend()
plt.xlabel(d_metric)

# %%

df = hr.cat_df('experiment', {
    'wave-norm': hr.results_df('data/results/plain_normed/vggvox_v000_pgd_wave_f'),
    'wave-pgd': hr.results_df('data/results/plain_pgd/vggvox_v000_pgd_wave_f'),
    'spec-norm': hr.results_df('data/results/plain_normed/vggvox_v000_pgd_spec_f')
})

print(df.to_string())

sns.lineplot(x='pesq', y='far1-mv', hue='experiment', marker='o', data=df)
# plt.gca().set_xscale('log')

# %% Scatter plots

scenario = 'avg-10 far-1'

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-far1-avg', gender_index=1)
plt.plot(x, y, 'o', alpha=0.5, label=f'black-box (NES) : PESQ={pesq:.1f}')

# x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'training')
# plt.plot(x, y, 'o', alpha=0.5, label=f'white-box : PESQ={pesq:.1f}')
# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('IR improvement for white-box vs black-box optimization')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

# %% Show optimization progress
# 

dirname = 'data/results/plain_normed/vggvox_v000_pgd_spec_f'
dirname = 'data/results/cloning/vggvox_v000_nes_cloning_f'
dirname = 'data/results/plain_normed/vggvox_v000_pgd_wave_m'
# dirname = 'data/results/cloning_grid/vggvox_v000_nes_cloning_f'
# dirname = 'data/results/transfer/thin_resnet_v000_pgd_wave_f'
# dirname = 'data/results/nes_normed/vggvox_v000_nes_wave_f'

# results, labels = hr.progress('data/results/plain_normed/vggvox_v000_pgd_wave_f', None)
results, labels = hr.progress(dirname, None, gender='m')
# results, labels = hr.progress('data/results/plain_pgd/vggvox_v000_pgd_wave_f', pad=True)

for k, progress in results.items():
    plt.plot(np.array(progress).mean(axis=0), '.-', label='$\lambda$=' + labels[k]['label'])
    # plt.plot(np.array(progress).T, '-', label='$\lambda$=' + labels[k]['label'])
    # plt.plot(np.percentile(progress, 90, axis=0), ':', label=labels[k]['label'])
    # plt.plot(np.percentile(progress, 10, axis=0), ':', label=labels[k]['label'])

plt.ylabel('far-1 IR')
plt.xlabel('Steps')
# plt.legend()
plt.title('Progress: f{}'.format(dirname.split('/')[-1]))

# %%

df = hr.cat_df('experiment', {
    'plain': hr.results_df('data/results/plain_normed/vggvox_v000_pgd_wave_f'),
    'play': hr.results_df('data/results/play_normed/vggvox_v000_pgd_wave_f'),
})

print(df.to_string())

sns.lineplot(x='pesq', y='far1-mv', hue='experiment', marker='o', data=df)

# %%

df = hr.results_df('data/results/cloning_grid/vggvox_v000_nes_cloning_f', None)
df = df.sort_values(['nes_n', 'nes_sigma', 'step_size'])

print(df.to_string())

# %% Transferability

df = hr.transferability('data/results/cloning', (0,), 1, play=0)
print(df.round(2).to_string())

# %%

x, y, pesq = hr.scatter('data/results/cloning/vggvox_v000_nes_cloning_f/v000/', 'vggvox_v000', gender_index=1)
plt.plot(x, y, 'o', alpha=0.5, label=f'black-box (NES) : PESQ={pesq:.1f}')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

# %%

from matplotlib import rc

# enable latex
rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})
rc('text', usetex=True)
rc('text.latex', preamble=r'\usepackage{amsmath}\usepackage{amssymb}')

# disable latex
rc('font', **{'family': 'serif'})
rc('text', usetex=False)

# %% Section A : Optimization domain and settings

plt.figure(figsize=(20,3), dpi=150)

dirname = 'data/results/plain_normed/vggvox_v000_pgd_wave_f'
results, labels = hr.progress(dirname, 'v00[1-9]', gender='f')

plt.subplot(1,4,2)
for k, progress in results.items():
    plt.plot(np.array(progress).mean(axis=0), '.-', label='$\lambda$=' + labels[k]['label'])

# plt.ylabel('master voice IR (any-10, far-1)')
plt.xlabel('Epochs')
plt.legend(loc='lower right')
plt.ylim([0, 0.75])
plt.gca().set_yticklabels([])
plt.title('Attack progress: {}'.format('waveform'))

# --

dirname = 'data/results/plain_pgd/vggvox_v000_pgd_wave_f'
results, labels = hr.progress(dirname, 'v00[1-9]', gender='f')

plt.subplot(1,4,3)
for k, progress in results.items():
    plt.plot(np.array(progress).mean(axis=0), '.-', label='$\lambda$=' + labels[k]['label'])

# plt.ylabel('master voice IR (any-10, far-1)')
plt.xlabel('Epochs')
plt.legend(loc='lower right')
plt.ylim([0, 0.75])
plt.gca().set_yticklabels([])
plt.title('Attack progress: waveform (BIM)')

# --

dirname = 'data/results/plain_normed/vggvox_v000_pgd_spec_f'
results, labels = hr.progress(dirname, None, gender='f')

plt.subplot(1,4,1)
for k, progress in results.items():
    plt.plot(np.array(progress).mean(axis=0), '.-', label='$\lambda$=' + labels[k]['label'])

plt.ylabel('master voice IR (any-10, far-1)')
plt.xlabel('Epochs')
plt.legend(loc='lower right')
plt.ylim([0, 0.75])
plt.title('Attack progress: {}'.format('spectrogram'))

# --

plt.subplot(1,4,4)

# Version 1 ----
# df = hr.cat_df('experiment', {
#     'spectrogram (L2 norm)': hr.results_df('data/results/plain_normed/vggvox_v000_pgd_spec_f'),
#     'waveform (L2 norm)': hr.results_df('data/results/plain_normed/vggvox_v000_pgd_wave_f', 'v00[1-9]'),
#     'waveform (BIM)': hr.results_df('data/results/plain_pgd/vggvox_v000_pgd_wave_f')
# })

# print(df.to_string())

# sns.lineplot(x='pesq', y='far1-mv', hue='experiment', marker='o', data=df)

# Version 2 ---

exp_labels = ('waveform ($L_2$)', 'waveform ($L_\infty$)', 'spectrum ($L_2$, after inversion)', 'spectrum ($L_2$, no inversion)')
measurements = ['vggvox_v000-any-far1'] * 3 + ['training']

for i, experiment in enumerate(('plain_normed/vggvox_v000_pgd_wave_f', 'plain_pgd/vggvox_v000_pgd_wave_f', 'plain_normed/vggvox_v000_pgd_spec_f', 'plain_normed/vggvox_v000_pgd_spec_f')):

    X, Y, P = [], [], []
    for v in range(9):
        try:
            x, y, p = hr.scatter(f'data/results/{experiment}/v{v:03d}/', measurements[i], gender_index=1)
            X.append(np.mean(x))
            Y.append(np.mean(y))
            P.append(np.mean(p))
        except:
            pass

    plt.plot(P, Y, '.-', label=exp_labels[i])

plt.xlabel('PESQ')
plt.ylim([0, 0.75])
plt.ylabel(None)
plt.gca().set_yticklabels([])
plt.title('Distortion vs. impersonation rate trade-off')
plt.legend(loc='lower right')

plt.savefig('data/results/a_progress.pdf', bbox_inches='tight')

# %% A : Table

df = pd.DataFrame(columns=['sv', 'm/sv', 'm/mv', 'f/sv', 'f/mv'])

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-far1', gender_index=1)
row = {'sv': 'avg-far1'}
row['f/sv'] = np.mean(100 * x)
row['f/mv'] = np.mean(100 * y)
x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_m/v005/', 'vggvox_v000-avg-far1', gender_index=0)
row['m/sv'] = np.mean(100 * x)
row['m/mv'] = np.mean(100 * y)
df = df.append(row, ignore_index=True)

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-eer', gender_index=1)
row = {'sv': 'avg-eer'}
row['f/sv'] = np.mean(100 * x)
row['f/mv'] = np.mean(100 * y)
x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_m/v005/', 'vggvox_v000-avg-eer', gender_index=0)
row['m/sv'] = np.mean(100 * x)
row['m/mv'] = np.mean(100 * y)
df = df.append(row, ignore_index=True)

# df.columns = pd.MultiIndex.from_tuples([c.split('/') for c in df.columns])

print(df.round(1))

# %%

# from collections import OrderedDict

df = pd.DataFrame(columns=['sv'])

versions_wave = range(1, 6)

for measurement in (
        'training', 
        'vggvox_v000-any-far1', 
        'vggvox_v000-avg-far1', 
        'vggvox_v000-avg-far1-avg', 
        'vggvox_v000-any-eer', 
        'vggvox_v000-avg-eer'
        ):
    
    row = {}
    row['sv'] = '-'.join(measurement.split('-')[1:]) if '-' in measurement else measurement

    for v in versions_wave:

        # females
        x, y, pesq_score = hr.scatter(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{v:03d}/', measurement, gender_index=1)
        row[f'f/_sv'] = 100 * np.mean(x)
        row[f'f/mv({v})'] = 100 * np.mean(y)
        
        # males
        x, y, pesq_score = hr.scatter(f'data/results/plain_normed/vggvox_v000_pgd_spec_m/v{v:03d}/', measurement, gender_index=0)
        row[f'm/_sv'] = 100 * np.mean(x)
        row[f'm/mv({v})'] = 100 * np.mean(y)
    
    df = df.append(row, ignore_index=True)

print(df.round(1).to_string())

# %% A : Spectrograms

def plot_spec(w1, w2, axes, titles=True):

    s1 = audio.get_np_spectrum(w1, normalized=False)
    s2 = audio.get_np_spectrum(w2, normalized=False)
    
    pesq_score = pesq.pesq(16000, w1, w2, 'wb')

    if s1.shape[1] > s2.shape[1]:
        s1 = s1[..., :s2.shape[1]]

    if s2.shape[1] > s1.shape[1]:
        s2 = s2[..., :s1.shape[1]]

    s1 = s1 / np.max(s1)
    s2 = s2 / np.max(s2)

    axes[0].imshow(np.log(0.01 + s1))
    axes[0].set_xticks([])
    axes[0].set_yticks([])
    if titles:
        axes[0].set_title('seed voice spectrum')
    
    axes[1].imshow(np.log(0.01 + s2))
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    if titles:
        axes[1].set_title(f'master voice (PESQ={pesq_score:.1f})')
    
    V = np.percentile(np.abs(s1 - s2), 99)
    axes[2].imshow(s2 - s1, vmin=-V, vmax=V, cmap='bwr')
    axes[2].set_xticks([])
    axes[2].set_yticks([])
    if titles:
        axes[2].set_title('difference')


# s1 = audio.get_np_spectrum(w1, normalized=False)[..., :256]

# TEMP Invert 
# s1 = audio.get_np_spectrum(w1, normalized=False, full=True)[..., :256].T
# s1 = audio.spectrum_to_signal(s1, int(2.57 * 16000))
# s1 = audio.get_np_spectrum(s1, normalized=False)

# s1 = np.load(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/sv/{sid:03d}.npy')
# s2 = np.load(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/mv/{sid:03d}.npy')

fig, axes = plt.subplots(4,3)
fig.set_size_inches((9,12))
fig.set_dpi(150)

# --
vid, sid = 5, 5
axes[0][0].set_ylabel(f'waveform opt. ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[0], True)

# --
vid, sid = 5, 2
axes[1][0].set_ylabel(f'waveform opt. ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[1], True)

# --
vid, sid = 3, 5
axes[2][0].set_ylabel(f'spectrum opt. ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[2], True)

# --
vid, sid = 3, 2
axes[3][0].set_ylabel(f'spectrum opt. ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_spec_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[3], True)

plt.savefig('data/results/a_spectrograms.pdf', bbox_inches='tight')

# %% B: Playback trade-off

exp_labels = ('standard opt. (f)', 'standard opt. (m)', 'opt. w/ playback (f)', 'opt. w/ playback (m)')
measurements = ['vggvox_v000-avg-far1'] * 4

fig, axes = plt.subplots(1,2)
fig.set_size_inches((10,3))
fig.set_dpi(150)

for i, experiment in enumerate(('plain_normed/vggvox_v000_pgd_wave_f', 
                                'plain_normed/vggvox_v000_pgd_wave_m', 
                                'play_normed/vggvox_v000_pgd_wave_f', 
                                'play_normed/vggvox_v000_pgd_wave_m'
                                )):

    gender_index = 1 if experiment[-1] == 'f' else 0
    
    for play in (1,0):
        X, Y, P = [], [], []
        for v in range(9):
            try:
                x, y, p = hr.scatter(f'data/results/{experiment}/v{v:03d}/', 
                                     measurements[i], gender_index=gender_index, play=play)
                X.append(np.mean(x))
                Y.append(np.mean(y))
                P.append(np.mean(p))
            except:
                pass
            
        if len(X) == 0:
            print(experiment)
    
        play_labels = []
        if experiment.startswith('play'):
            play_labels.append('opt.')
        if play:
            play_labels.append('test')
          
        plt.subplot(1, 2, 2 - gender_index)
        play_label = ', '.join(play_labels)
        plt.plot(P, Y, f'-C{i}' if play else f':C{i}', label=f'playback during {play_label}')

    plt.xlabel('PESQ')
    # plt.ylim([0, 0.75])
    plt.xlim([1, 4.8])
    plt.ylabel('master voice IR (avg, far1)' if gender_index == 1 else None)
    # plt.gca().set_yticklabels([])
    plt.title('female speakers' if gender_index == 1 else 'male speakers')
    plt.legend(loc='lower left')

plt.savefig('data/results/b_tradeoff.pdf', bbox_inches='tight', dpi=150)

# %% B : Playback Simulation

scenario = 'avg-10 far-1'

plt.figure(figsize=(10,3))
plt.subplot(1,2,1)

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-far1', gender_index=1)
# plt.plot(x, y, 's', alpha=0.35, label=f'no playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'no playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-far1', play=True, gender_index=1)
# plt.plot(x, y, 'x', alpha=0.35, label=f'tested with playback (PESQ={pesq:.1f})')
# plotting.correlation(x, y, guide=True, marginals=True)
plotting.scatter(x, y, 's', f'tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/play_normed/vggvox_v000_pgd_wave_f/v001/', 'vggvox_v000-avg-far1', play=True, gender_index=1)
# plt.plot(x, y, 'o', alpha=0.35, label=f'optimized and tested with playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'opt. \\& tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/play_normed/vggvox_v000_pgd_wave_f/v004/', 'vggvox_v000-avg-far1', play=True, gender_index=1)
# plt.plot(x, y, 'o', alpha=0.35, label=f'optimized and tested with playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'opt. \\& tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('female speakers')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
# plt.legend(loc='lower right')

plt.subplot(1,2,2)

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_m/v005/', 'vggvox_v000-avg-far1', gender_index=0)
# plt.plot(x, y, 's', alpha=0.35, label=f'no playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'no playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_m/v005/', 'vggvox_v000-avg-far1', play=True, gender_index=0)
# plt.plot(x, y, 'x', alpha=0.35, label=f'tested with playback (PESQ={pesq:.1f})')
# plotting.correlation(x, y, guide=True, marginals=True)
plotting.scatter(x, y, 's', f'tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/play_normed/vggvox_v000_pgd_wave_m/v001/', 'vggvox_v000-avg-far1', play=True, gender_index=0)
# plt.plot(x, y, 'o', alpha=0.35, label=f'optimized and tested with playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'opt. \\& tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

x, y, pesq = hr.scatter('data/results/play_normed/vggvox_v000_pgd_wave_m/v004/', 'vggvox_v000-avg-far1', play=True, gender_index=0)
# plt.plot(x, y, 'o', alpha=0.35, label=f'optimized and tested with playback (PESQ={pesq:.1f})')
plotting.scatter(x, y, 's', f'opt. \\& tested with playback (PESQ={pesq:.1f})', marginals='y', axes=plt.gca(), xlim=[0, 1], ylim=[0, 1])

# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('male speakers')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
# plt.ylabel(f'master voice IR ({scenario})')
plt.legend(loc='lower right')

plt.savefig('data/results/b_playback.pdf', bbox_inches='tight', dpi=150)

# %% B : Playback Spectrograms

fig, axes = plt.subplots(2,3)
fig.set_size_inches((10,6.66))
fig.set_dpi(150)

sid = 22

# --
vid = 5
axes[0][0].set_ylabel(f'no playback ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/plain_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[0], True)

# --

# ir_2 = np.load(f'data/results/play_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/mv_test_population_interspeech_1000u_10s-vggvox_v000-avg-far1-1.npz', allow_pickle=True)['results']
# ir_2 = valid.item()['imps'][sid, :].mean()

vid = 2
axes[1][0].set_ylabel(f'with playback ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/play_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/play_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[1], True)

plt.savefig('data/results/b_spectrograms.pdf', bbox_inches='tight')

# %%
# Test
from helpers import audio
import tensorflow as tf
tf.config.set_visible_devices([], 'gpu')
from models import verifier
from helpers.dataset import Dataset

# Build and load pre-trained weights of a sv
sv = verifier.get_model('vggvox/v000')
sv.build(classes=0, mode='test')
sv.load()
sv.calibrate_thresholds()
sv.infer()
sv.setup_playback()

# Create the test gallery
test_gallery = Dataset('data/vs_mv_pairs/mv_test_population_interspeech_1000u_10s.csv')
test_gallery.precomputed_embeddings(sv)

sv.test_error_rates(w1, test_gallery, 'avg', 'far1', playback=True)


# %%

# %% ...

scenario = 'avg-10 far-1'

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_spec_f/v001/', 'vggvox_v000-avg-far1')
plt.plot(x, y, 'o', alpha=0.5, label=f'black-box (NES) : PESQ={pesq:.1f}')

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'training')
plt.plot(x, y, 'o', alpha=0.5, label=f'white-box : PESQ={pesq:.1f}')
# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('IR improvement for white-box vs black-box optimization')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

# %% Section C : Black-box vs. white-box optimization

scenario = 'avg-10 far-1'

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
x, y, pesq = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000-avg-far1')
plt.plot(x, y, 'o', alpha=0.5, label=f'black-box (NES) : PESQ={pesq:.1f}')

x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_f/v005/', 'vggvox_v000-avg-far1')
plt.plot(x, y, 'o', alpha=0.5, label=f'white-box : PESQ={pesq:.1f}')
# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('white-box vs black-box optimization (VGGVox)')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

plt.subplot(1,2,2)
x, y, pesq = hr.scatter('data/results/nes_normed/xvector_v000_nes_wave_f/v000/', 'training')
plt.plot(x, y, 'o', alpha=0.5, label=f'black-box (NES) : PESQ={pesq:.1f}')

# x, y, pesq = hr.scatter('data/results/plain_normed/vggvox_v000_pgd_wave_m/v005/', 'vggvox_v000-avg-far1')
# plt.plot(x, y, 'o', alpha=0.5, label=f'white-box : PESQ={pesq:.1f}')
# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

plt.title('black-box optimization (X-vector)')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

plt.savefig('data/results/c_blackbox_scatters.pdf', bbox_inches='tight')

# %% C : Black-box spectrograms

fig, axes = plt.subplots(2,3)
fig.set_size_inches((10,6.66))
fig.set_dpi(150)

sid = 5

# --
vid = 0
axes[0][0].set_ylabel(f'VGGVox ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/nes_normed/vggvox_v000_nes_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/nes_normed/vggvox_v000_nes_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[0], True)

# --

# ir_2 = np.load(f'data/results/play_normed/vggvox_v000_pgd_wave_f/v{vid:03d}/mv/mv_test_population_interspeech_1000u_10s-vggvox_v000-avg-far1-1.npz', allow_pickle=True)['results']
# ir_2 = valid.item()['imps'][sid, :].mean()

vid = 0
axes[1][0].set_ylabel(f'X-vector ({sid:03d}.wav)')
w1 = audio.decode_audio(f'data/results/nes_normed/xvector_v000_nes_wave_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/nes_normed/xvector_v000_nes_wave_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[1], True)

plt.savefig('data/results/c_spectrograms.pdf', bbox_inches='tight')

# %%

# %% D : Transferability

df = hr.transferability('data/results/transfer', (0,2), 1, play=1)
print(df.round(2).to_string())

# %% F: Cloning

df = hr.results_df('data/results/cloning_grid/vggvox_v000_nes_cloning_f', None)
df = df.sort_values(['nes_n', 'nes_sigma', 'step_size'])

print(df.to_string())

# %% F: Cloning Transferability

df = hr.transferability('data/results/cloning', (0,), 0, play=0)
print(df.round(2).to_string())

# %% F : Cloning

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
dirname = 'data/results/cloning_play/vggvox_v000_nes_cloning_f'

results, labels = hr.progress(dirname, None, gender=dirname[-1])

for k, progress in results.items():
    plotting.intervals(range(np.array(progress).shape[1]), np.array(progress), axes=plt.gca())

plt.ylabel('master voice IR (avg, far-1)')
plt.xlabel('Epochs')
# plt.legend()
# plt.title('Progress: f{}'.format(dirname.split('/')[-1]))

dirname = 'data/results/cloning_play/vggvox_v000_nes_cloning_m'

results, labels = hr.progress(dirname, None, gender=dirname[-1])

for k, progress in results.items():
    plotting.intervals(range(np.array(progress).shape[1]), np.array(progress), axes=plt.gca())

plt.ylabel('master voice IR (avg, far-1)')
plt.xlabel('Epochs')
# plt.legend()
# plt.title('Progress: f{}'.format(dirname.split('/')[-1]))

plt.subplot(1,2,2)
scenario = 'avg-10 far-1'

x, y, _ = hr.scatter('data/results/cloning_play/vggvox_v000_nes_cloning_f/v000/', 'vggvox_v000-avg-far1')
plt.plot(x, y, 'o', alpha=0.5, label=f'female')

x, y, _ = hr.scatter('data/results/cloning_play/vggvox_v000_nes_cloning_m/v000', 'training')
plt.plot(x, y, 'o', alpha=0.5, label=f'male')
# x, y = hr.scatter('data/results/nes_normed/vggvox_v000_nes_wave_f/v000/', 'vggvox_v000')

# plt.title('IR improvement for white-box vs bl.ack-box optimization')
plt.plot([0, 1], [0, 1], 'k:')
plt.xlabel(f'seed IR ({scenario})')
plt.ylabel(f'master voice IR ({scenario})')
plt.legend()

plt.savefig('data/results/f_cloning.pdf', bbox_inches='tight')

# %% F : Spectrograms

def plot_spec(w1, w2, axes, titles=True):

    s1 = audio.get_np_spectrum(w1, normalized=False)
    s2 = audio.get_np_spectrum(w2, normalized=False)
    
    pesq_score = pesq.pesq(16000, w1, w2, 'wb')

    if s1.shape[1] > s2.shape[1]:
        s1 = s1[..., :s2.shape[1]]

    if s2.shape[1] > s1.shape[1]:
        s2 = s2[..., :s1.shape[1]]

    s1 = s1 / np.max(s1)
    s2 = s2 / np.max(s2)

    axes[0].imshow(np.log(0.01 + s1))
    axes[0].set_xticks([])
    axes[0].set_yticks([])
    if titles:
        axes[0].set_title('seed voice spectrum')
    
    axes[1].imshow(np.log(0.01 + s2))
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    if titles:
        axes[1].set_title(f'master voice (PESQ={pesq_score:.1f})')
    
    if len(axes) > 2:
        V = np.percentile(np.abs(s1 - s2), 99)
        axes[2].imshow(s2 - s1, vmin=-V, vmax=V, cmap='bwr')
        axes[2].set_xticks([])
        axes[2].set_yticks([])
        if titles:
            axes[2].set_title('difference')


fig, axes = plt.subplots(2,2)
fig.set_size_inches((9,9))
fig.set_dpi(150)

# --
vid, sid = 0, 8
axes[0][0].set_ylabel(f'seed = {sid:03d}.wav')
w1 = audio.decode_audio(f'data/results/cloning_play/vggvox_v000_nes_cloning_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/cloning_play/vggvox_v000_nes_cloning_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[0], True)

# --
vid, sid = 0, 2
axes[1][0].set_ylabel(f'seed = {sid:03d}.wav')
w1 = audio.decode_audio(f'data/results/cloning_play/vggvox_v000_nes_cloning_f/v{vid:03d}/sv/{sid:03d}.wav', target_length=None)
w2 = audio.decode_audio(f'data/results/cloning_play/vggvox_v000_nes_cloning_f/v{vid:03d}/mv/{sid:03d}.wav', target_length=None)
plot_spec(w1, w2, axes[1], True)

plt.savefig('data/results/f_spectrograms.pdf', bbox_inches='tight')
