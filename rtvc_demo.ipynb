{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bc9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4fd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e7698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import librosa\n",
    "import sounddevice\n",
    "sys.path.append('rtvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1d4e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
      "Trainable Parameters: 4.481M\n"
     ]
    }
   ],
   "source": [
    "from rtvc import rtvc_api\n",
    "\n",
    "rtvc_api.load_models('rtvc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f63cae",
   "metadata": {},
   "source": [
    "## RTVC Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "421ae037",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_speaker = 'data/librispeech/1040/133433/1040-133433-0002.flac'\n",
    "target_speaker = 'data/vctk/p234/p234_003.wav'\n",
    "source, sf = librosa.load(target_speaker, sr=16000)\n",
    "sounddevice.play(source, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1c33e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = rtvc_api.get_embedding(target_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8728c5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([167.,  21.,  22.,  21.,   6.,   7.,   4.,   4.,   2.,   2.]),\n",
       " array([0.        , 0.02562771, 0.05125542, 0.07688312, 0.10251083,\n",
       "        0.12813854, 0.15376624, 0.17939396, 0.20502166, 0.23064938,\n",
       "        0.25627708], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d69683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{| ████████████████ 437000/441600 | Batch Size: 46 | Gen Rate: 71.7kHz | }Waveform: (372480,)\n"
     ]
    }
   ],
   "source": [
    "waveform = rtvc_api.vc('Okay, google! Please buy bitcoin!', embed + 10)\n",
    "print(f'Waveform: {waveform.shape}')\n",
    "sounddevice.play(waveform, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73a400bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounddevice.play(waveform, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93f80d",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f388de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb81e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.dataset import filter_by_gender, Dataset\n",
    "from helpers.datapipeline import data_pipeline_mv\n",
    "\n",
    "from models import verifier\n",
    "from models.mv.model import SiameseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d0b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 11:30:56.116 | INFO     | helpers.dataset:filter_by_gender:216 - Filter data sets by gender\n",
      "2021-11-12 11:30:56.118 | INFO     | helpers.dataset:filter_by_gender:231 - Filtered by female: 120 audio files from 12 users\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('data/vs_mv_pairs/mv_train_population_vctk_20u_10s.csv')\n",
    "x_train, y_train = train_set['filename'], train_set['user_id']\n",
    "x_train, y_train = filter_by_gender(x_train, y_train, 'data/vs_mv_pairs/meta_data_vctk.csv', 'female')\n",
    "assert len(x_train) > 0, 'Looks like no user data was loaded! Check your data directories and gender filters'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824b46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_pipeline_mv(x_train, y_train, int(16000 * 2.58), 16000, 20, 120, 'spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d720671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 11:42:10.359 | INFO     | helpers.dataset:save_embeddings:65 - (200, 512)\n",
      "2021-11-12 11:42:10.360 | INFO     | helpers.dataset:save_embeddings:67 - Embeddings saved for data/vs_mv_data/mv_test_population_vctk_20u_10s/embeddings/vggvox_v000.npz\n"
     ]
    }
   ],
   "source": [
    "test_gallery = Dataset('data/vs_mv_pairs/mv_test_population_vctk_20u_10s.csv')\n",
    "test_gallery.precomputed_embeddings(sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21593335",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_gallery.population.shape[0] == test_gallery.embeddings.shape[0], \"Number of fetched embeddings does not match #people in the population. Outdated cache?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d725565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6348d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 11:31:03.502 | DEBUG    | models.mv.model:__init__:72 - Output dir exists: data/vs_mv_data/temp_vctk/v000\n",
      "2021-11-12 11:31:03.503 | INFO     | models.verifier.model:__init__:123 - created model folder ./data/vs_mv_models/vggvox/v000\n",
      "2021-11-12 11:31:03.503 | INFO     | models.verifier.vggvox:build:47 - building vggvox for 0 classes\n",
      "2021-11-12 11:31:03.937 | INFO     | models.verifier.model:load:184 - loading pre-trained vggvox\n",
      "2021-11-12 11:31:03.938 | DEBUG    | models.verifier.model:load:189 - ./data/vs_mv_models/vggvox/v000/model.h5\n",
      "2021-11-12 11:31:04.556 | INFO     | models.verifier.model:load:194 - loaded checkpoint from ./data/vs_mv_models/vggvox/v000\n"
     ]
    }
   ],
   "source": [
    "# dir_name = utils.sanitize_path(f'{args.netv}_{args.attack}_{args.mv_gender[0]}'.replace('/', '_'))\n",
    "dir_name = 'temp_vctk'\n",
    "dir_name = os.path.join('data', 'vs_mv_data', dir_name)\n",
    "\n",
    "args = SimpleNamespace()\n",
    "\n",
    "# Basic setup\n",
    "siamese_model = SiameseModel(dir=dir_name,\n",
    "                             params=args, \n",
    "                             playback=False, \n",
    "                             ir_dir='data/vs_noise_data/',\n",
    "                             run_id=0)\n",
    "\n",
    "# Set verifier\n",
    "sv = verifier.get_model('vggvox/v000')\n",
    "siamese_model.set_verifier(sv)\n",
    "\n",
    "# Build model\n",
    "siamese_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12c8ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.mv.model.SiameseModel.defaults.<locals>.AttrDict object at 0x7fa142fd4750>\n"
     ]
    }
   ],
   "source": [
    "opt_settings = siamese_model.defaults()\n",
    "\n",
    "print(opt_settings)\n",
    "\n",
    "# opt_settings.update({\n",
    "#     'gradient': args.gradient,\n",
    "#     'n_epochs': args.n_epochs,\n",
    "#     'max_attack_vector': args.max_dist,\n",
    "#     'l2_regularization': args.l2_reg,\n",
    "#     'learning_rate': args.learning_rate\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b1deb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
      "Trainable Parameters: 4.481M\n"
     ]
    }
   ],
   "source": [
    "import rtvc_api\n",
    "rtvc_api.load_models('rtvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3a994ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 12:15:33.964 | INFO     | models.mv.model:batch_optimize_by_path:232 - Starting optimization data/vs_mv_seed/female/001.wav: 1 of 1\n",
      "2021-11-12 12:15:33.980 | DEBUG    | models.mv.model:optimize:297 - Configured optimization: parameter space (256,)\n",
      "2021-11-12 12:15:33.985 | INFO     | models.verifier.model:test_error_rates:310 - used thresholds {'eer': 0.7683, 'far1': 0.8343}\n",
      "2021-11-12 12:15:34.106 | INFO     | models.verifier.model:test_error_rates:310 - used thresholds {'eer': 0.7683, 'far1': 0.8343}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
      "Trainable Parameters: 4.481M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 12:15:34.202 | DEBUG    | models.mv.model:optimize:310 - (Baseline) Imp@EER m=0.000 f=0.000 | Imp@FAR1 m=0.000 f=0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 30.870M\n",
      "+----------+---+\n",
      "| Tacotron | r |\n",
      "+----------+---+\n",
      "|   295k   | 2 |\n",
      "+----------+---+\n",
      " \n",
      "{| ████████████████ 38000/38400 | Batch Size: 4 | Gen Rate: 6.7kHz | }"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 12:28:51.873 | INFO     | models.verifier.model:test_error_rates:310 - used thresholds {'eer': 0.7683, 'far1': 0.8343}\n",
      "2021-11-12 12:28:52.092 | INFO     | models.verifier.model:test_error_rates:310 - used thresholds {'eer': 0.7683, 'far1': 0.8343}\n",
      "2021-11-12 12:28:52.174 | DEBUG    | models.mv.model:optimize:351 - (Epoch= 0) Imp@EER m=0.125 f=0.583 | Imp@FAR1 m=0.000 f=0.000 | opt time 791.7 + val time 6.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{| ███████████░░░░░ 31000/48000 | Batch Size: 5 | Gen Rate: 7.9kHz | }"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8236f209c61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nes@cloning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pgd@spec, nes@cloning, pgd@wave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_optimize_by_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/vs_mv_seed/female/001.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/model.py\u001b[0m in \u001b[0;36mbatch_optimize_by_path\u001b[0;34m(self, seed_voice, train_data, test_gallery, settings)\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Clipping speech to {max_length} samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0minput_sv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0minput_mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gallery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv_gender\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Gender selector: 'm' or 'f'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, input_sv, train_data, test_gallery, settings)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mepoch_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_similarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/attacks.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, seed_sample, attack_vector, train_data, settings)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantithetic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gradient shape mismatch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/attacks.py\u001b[0m in \u001b[0;36m_nes\u001b[0;34m(input, f, n, sigma, antithetic)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mantithetic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mantithetic\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/attacks.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(attack_vector)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0minput_mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# if the received sample is too short, pad with zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mmin_lenght\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.57\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/models/mv/attacks.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, seed_sample, attack_vector)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mattack_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0minput_mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtvc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.58\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/rtvc/rtvc_api.py\u001b[0m in \u001b[0;36mvc\u001b[0;34m(text, speaker)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mclip_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mgenerated_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m## Post-generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/rtvc/vocoder/inference.py\u001b[0m in \u001b[0;36minfer_waveform\u001b[0;34m(mel, normalize, batched, target, overlap, progress_callback)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_max_abs_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mwav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_law\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/dl-master-voices/rtvc/vocoder/models/fatchord_version.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, mels, batched, target, overlap, mu_law, progress_callback)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/mv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/mv/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "siamese_model.setup_attack('nes@cloning', None) # pgd@spec, nes@cloning, pgd@wave\n",
    "siamese_model.batch_optimize_by_path('data/vs_mv_seed/female/001.wav', train_data, test_gallery, settings=opt_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58f9a1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gallery.population.shape[0], test_gallery.embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d6fd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/vs_mv_pairs/mv_test_population_vctk_20u_10s.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
