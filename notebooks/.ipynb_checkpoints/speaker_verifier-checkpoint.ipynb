{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking ASVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "- nets ['arch/vxxx']: comma-separated list of ASVs to test\n",
    "- tars [None, 1.0, 0.1]: comma-separated list of false acceptance levels to test (None stands for EER level)\n",
    "- pols ['avg', 'any']: comma-separated list of verification policies to test\n",
    "- thrs_types [None, 'avg', 'any']: comma-separated list of thresholds to select across policies (None stands for EER level)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = ['resnet50/v001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars = [None, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pols = ['avg10', 'any']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrs_types = [None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneThreshold(scores, labels, target_fa=None):\n",
    "    far, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    frr = 1 - tpr\n",
    "    frr = frr*100\n",
    "    far = far*100\n",
    "    if target_fa:\n",
    "        idx = np.nanargmin(np.absolute((target_fa - far))) \n",
    "        return thresholds[idx], far[idx], frr[idx]\n",
    "    idxE = np.nanargmin(np.absolute((frr - far)))\n",
    "    eer  = max(far[idxE], frr[idxE])\n",
    "    return thresholds[idxE], far[idxE], frr[idxE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_far(targets, similarities, thr):\n",
    "    fars = 0\n",
    "    count = 0\n",
    "    for t, s in zip(targets, similarities):\n",
    "        if t == 0:\n",
    "            if s >= thr:\n",
    "                fars += 1\n",
    "            count += 1\n",
    "    return fars / count * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frr(targets, similarities, thr):\n",
    "    frrs = 0\n",
    "    count = 0\n",
    "    for t, s in zip(targets, similarities):\n",
    "        if t == 1:\n",
    "            if s < thr:\n",
    "                frrs += 1\n",
    "            count += 1\n",
    "    return frrs / count * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox1_test_results = {}\n",
    "for net in nets:\n",
    "    vox1_test_results[net] = pd.read_csv(os.path.join('../data/pt_models', net, 'test_vox1_sv_test.csv'))\n",
    "    vox1_test_results[net] = vox1_test_results[net].loc[:, ~vox1_test_results[net].columns.str.contains('^Unnamed')]\n",
    "    vox1_test_results[net].columns = ['label', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_results = {}\n",
    "for net in nets:\n",
    "    train_history_results[net] = pd.read_csv(os.path.join('../data/pt_models', net, 'history.csv'))\n",
    "    train_history_results[net] = train_history_results[net].loc[:, ~train_history_results[net].columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupScores(scores, labels, thrs_type, size=8):\n",
    "    if thrs_type is None:\n",
    "        return scores, labels\n",
    "    func = np.mean if thrs_type == 'avg' else np.max\n",
    "    grp_scores, grp_labels = [], []\n",
    "    for i in range(0, len(scores), size):\n",
    "        curr_scores = scores[i:i+size]\n",
    "        grp_scores.append(func(curr_scores[1::2]))\n",
    "        grp_labels.append(0)\n",
    "        grp_scores.append(func(curr_scores[0::2]))\n",
    "        grp_labels.append(1)\n",
    "    return grp_scores, grp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress = {}\n",
    "thrs = {}\n",
    "for thrs_type in thrs_types:\n",
    "    ress[thrs_type] = {}\n",
    "    thrs[thrs_type] = {}\n",
    "    for tar in tars:\n",
    "        ress[thrs_type][tar] = {}\n",
    "        thrs[thrs_type][tar] = {}\n",
    "        for net in nets:\n",
    "            loss = train_history_results[net]['loss'].values[-1]\n",
    "            acc = train_history_results[net]['acc'].values[-1]\n",
    "            if thrs_type is None:\n",
    "                thr, far, frr = tuneThreshold(vox1_test_results[net]['score'].values, vox1_test_results[net]['label'].values, tar)\n",
    "                thrs[thrs_type][tar][net] = thr\n",
    "                ress[thrs_type][tar][net] = [np.mean([far, frr]), far, frr, thr, len(vox1_test_results[net].index), loss, acc]\n",
    "            else:\n",
    "                grp_scores, grp_labels = groupScores(vox1_test_results[net]['score'].values, vox1_test_results[net]['label'].values, thrs_type)\n",
    "                thr = thrs[None][tar][net]\n",
    "                far = count_far(grp_labels, grp_scores, thr)\n",
    "                frr = count_frr(grp_labels, grp_scores, thr)\n",
    "                ress[thrs_type][tar][net] = [np.mean([far, frr]), far, frr, thr, len(vox1_test_results[net].index), loss, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">raw  EER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>eer</th>\n",
       "      <th>far</th>\n",
       "      <th>frr</th>\n",
       "      <th>thr</th>\n",
       "      <th>no-trials</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50/v001</th>\n",
       "      <td>5.7688</td>\n",
       "      <td>5.7688</td>\n",
       "      <td>5.7688</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>37720</td>\n",
       "      <td>2.3848</td>\n",
       "      <td>0.6683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">raw  FAR@1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>eer</th>\n",
       "      <th>far</th>\n",
       "      <th>frr</th>\n",
       "      <th>thr</th>\n",
       "      <th>no-trials</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50/v001</th>\n",
       "      <td>11.2778</td>\n",
       "      <td>1.0021</td>\n",
       "      <td>21.5536</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>37720</td>\n",
       "      <td>2.3848</td>\n",
       "      <td>0.6683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for thrs_type in thrs_types:\n",
    "    for tar in tars:\n",
    "        tar_label = (thrs_type if thrs_type is not None else 'raw') + '  ' + ('FAR@'+str(tar) if tar is not None else 'EER')\n",
    "        df = pd.DataFrame.from_dict(ress[thrs_type][tar], orient='index', columns=['eer', 'far', 'frr', 'thr', 'no-trials', 'loss', 'acc'])\n",
    "        df.columns = pd.MultiIndex.from_tuples([(tar_label,'eer'), (tar_label,'far'), (tar_label,'frr'), (tar_label, 'thr'), (tar_label, 'no-trials'), (tar_label, 'loss'), (tar_label, 'acc')])\n",
    "        df.style.set_properties(**{'width':'10em', 'text-align':'center'})\n",
    "        df.sort_index(inplace=True)\n",
    "        display(HTML(df.to_html()))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark MV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeImpersonation(fp, thr, pol, size=10):\n",
    "    df = pd.read_csv(fp)\n",
    "    imp_m, tot_m = 0, 0\n",
    "    imp_f, tot_f = 0, 0\n",
    "    user_ids_f, user_ids_m = [], []\n",
    "    for i in range(0, len(df), size): \n",
    "        user_id = i // size\n",
    "        tot_f += 1 if df.loc[i, 'gender'] == 'f' else 0\n",
    "        tot_m += 1 if df.loc[i, 'gender'] == 'm' else 0\n",
    "        imp_r = len([i for i in df.loc[i:i+size-1, 'score'] if i >= thr]) if pol == 'any' else (1 if np.mean(df.loc[i:i+size-1, 'score']) > thr else 0)\n",
    "        imp_f += 1 if df.loc[i, 'gender'] == 'f' and imp_r > 0 else 0\n",
    "        imp_m += 1 if df.loc[i, 'gender'] == 'm' and imp_r > 0 else 0\n",
    "        user_ids_f += [user_id] if df.loc[i, 'gender'] == 'f' and imp_r > 0 else []\n",
    "        user_ids_m += [user_id] if df.loc[i, 'gender'] == 'm' and imp_r > 0 else []\n",
    "    assert imp_m / tot_m <= 1.0 and imp_f / tot_f <= 1.0\n",
    "    return imp_m, imp_f, user_ids_m, user_ids_f, tot_m, tot_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-ddb148ee36e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                             \u001b[0mmv_test_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmvset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpols\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg10'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         \u001b[0mmv_test_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmvset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmvsam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeImpersonation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v001'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvsam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                         print('>\\r', pol, '(' + str(i1+1) + '/' + str(len(pols)) + ')', tar, '(' + str(i2+1) + '/' + str(len(tars)) + ')', \n\u001b[1;32m     21\u001b[0m                                      net, '(' + str(i3+1) + '/' + str(len(nets)) + ')',  mvset, '('+str(i4+1)+'/'+str(len(os.listdir(dp))) +')', end='')\n",
      "\u001b[0;32m<ipython-input-80-01c1617a4fbb>\u001b[0m in \u001b[0;36mcomputeImpersonation\u001b[0;34m(fp, thr, pol, size)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0muser_ids_f\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimp_r\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0muser_ids_m\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'm'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimp_r\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mimp_m\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtot_m\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimp_f\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtot_f\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimp_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ids_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ids_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "mv_test_results = {}\n",
    "for i1, pol in enumerate(pols):\n",
    "    mv_test_results[pol] = {}\n",
    "    for i2, tar in enumerate(tars):\n",
    "        mv_test_results[pol][tar] = {}\n",
    "        for i3, net in enumerate(nets):\n",
    "            mv_test_results[pol][tar][net] = {}\n",
    "            dp = os.path.join('../data/pt_models', net, 'mvcmp_' + pol)\n",
    "            for i4, mvset in enumerate(os.listdir(os.path.join(dp))): \n",
    "                if mvset.startswith('.'):\n",
    "                    continue\n",
    "                for mvsam in os.listdir(os.path.join(dp, mvset, 'v001')):\n",
    "                    if mvsam.startswith('.'):\n",
    "                        continue\n",
    "                    if int(mvsam.split('.')[0].split('_')[-1]) <=5:\n",
    "                        if mvset not in mv_test_results[pol][tar][net]:\n",
    "                            mv_test_results[pol][tar][net][mvset] = {}\n",
    "                        s = 0 if pols == 'avg10' else 10\n",
    "                        mv_test_results[pol][tar][net][mvset][mvsam] = computeImpersonation(os.path.join(dp, mvset, 'v001', mvsam), thrs[None][tar][net], pol, size=s) \n",
    "                        print('>\\r', pol, '(' + str(i1+1) + '/' + str(len(pols)) + ')', tar, '(' + str(i2+1) + '/' + str(len(tars)) + ')', \n",
    "                                     net, '(' + str(i3+1) + '/' + str(len(nets)) + ')',  mvset, '('+str(i4+1)+'/'+str(len(os.listdir(dp))) +')', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeData(data, ress, no_trials=1):\n",
    "    for mvset, mvsamps in data.items():\n",
    "        imp_m = []\n",
    "        imp_f = []\n",
    "        if no_trials <= 1:\n",
    "            for mvsam, mvress in mvsamps.items():\n",
    "                imp_m.append(mvress[0] / mvress[4])\n",
    "                imp_f.append(mvress[1] / mvress[5])\n",
    "        else:\n",
    "            keys = list(mvsamps.keys())\n",
    "            keys.sort()\n",
    "            tot_m, tot_f = 0, 0\n",
    "            for t in range(min(no_trials, len(keys))):\n",
    "                imp_m += mvsamps[keys[t]][2]\n",
    "                imp_f += mvsamps[keys[t]][3]\n",
    "                tot_m = mvsamps[keys[t]][4]\n",
    "                tot_f = mvsamps[keys[t]][5]\n",
    "            imp_m = [len(set(imp_m)) / tot_m]\n",
    "            imp_f = [len(set(imp_f)) / tot_f]\n",
    "        if mvset not in ress:\n",
    "            ress[mvset] = [round(np.mean(imp_m)*100,2), round(np.mean(imp_f)*100,2)]\n",
    "        else:\n",
    "            ress[mvset] += [round(np.mean(imp_m)*100,2), round(np.mean(imp_f)*100,2)]\n",
    "    return ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = ['resnet50/v001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pol in pols:\n",
    "    for tar in tars:\n",
    "        ress = {}\n",
    "        cols = []\n",
    "        for net in nets:\n",
    "            ress = arrangeData(mv_test_results[pol][tar][net], ress, no_trials=1) \n",
    "            cols += [net + '-m', net + '-f']\n",
    "        tar_label = pol.upper() + '  ' + ('FAR@'+str(tar) if tar is not None else 'EER')\n",
    "        df = pd.DataFrame.from_dict(ress, orient='index', columns=cols)\n",
    "        df = df.mask(df==0).fillna('-')\n",
    "        df.sort_index(inplace=True)\n",
    "        df.columns = pd.MultiIndex.from_tuples([(tar_label, col.split('-')[0], col.split('-')[1]) for col in cols])\n",
    "        df.style.set_properties(**{'width':'10em', 'text-align':'center'})\n",
    "        display(HTML(df.to_html()))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
