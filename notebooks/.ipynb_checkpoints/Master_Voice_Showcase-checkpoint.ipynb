{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Optimization for Dictionary Attacks on Speaker Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import decimal \n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input, Dot\n",
    "import librosa\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from scipy import spatial\n",
    "from scipy.signal import lfilter\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please open this Notebook on Prince Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj,name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Acoustic Features Extraction: Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set the parameters for spectrogram extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_params = {'max_sec': 10, 'bucket_step': 1, 'frame_step': 0.01, 'sample_rate': 16000, 'preemphasis_alpha': 0.97, 'frame_len': 0.025, 'num_fft': 512}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_spectrum(filename, params):\n",
    "    signal = load_wav(filename, params['sample_rate'])\n",
    "    frames = framesig(signal, frame_len=params['frame_len'] * params['sample_rate'], frame_step=params['frame_step']*params['sample_rate'], winfunc=np.hamming)\n",
    "    fft = abs(np.fft.fft(frames,n=params['num_fft']))\n",
    "    fft_norm, fft_means, fft_stds = normalize_frames(fft.T)\n",
    "    return fft_norm, fft_means, fft_stds\n",
    "\n",
    "def load_wav(filename, sample_rate):\n",
    "    audio, sr = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "    audio = audio.flatten()\n",
    "    return audio\n",
    "\n",
    "def framesig(sig, frame_len, frame_step, winfunc=lambda x: np.ones((x,)), stride_trick=True):\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step)) # LV\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = np.zeros((padlen - slen,))\n",
    "    padsignal = np.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
    "    else:\n",
    "        indices = np.tile(np.arange(0, frame_len), (numframes, 1)) + np.tile(np.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "        indices = np.array(indices, dtype=np.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = np.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: np.ones((x,))):\n",
    "    frame_len = round_half_up(frame_len)\n",
    "    frame_step = round_half_up(frame_step)\n",
    "    numframes = np.shape(frames)[0]\n",
    "    assert np.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_len), (numframes, 1)) + np.tile(\n",
    "        np.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "    indices = np.array(indices, dtype=np.int32)\n",
    "    padlen = (numframes - 1) * frame_step + frame_len\n",
    "\n",
    "    if siglen <= 0: siglen = padlen\n",
    "\n",
    "    rec_signal = np.zeros((padlen,))\n",
    "    window_correction = np.zeros((padlen,))\n",
    "    win = winfunc(frame_len)\n",
    "\n",
    "    for i in range(0, numframes):\n",
    "        window_correction[indices[i, :]] = window_correction[\n",
    "                                               indices[i, :]] + win + 1e-15  # add a little bit so it is never zero\n",
    "        rec_signal[indices[i, :]] = rec_signal[indices[i, :]] + frames[i, :]\n",
    "\n",
    "    rec_signal = rec_signal / window_correction\n",
    "    return rec_signal[0:siglen]\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "def normalize_frames(m,epsilon=1e-12):\n",
    "    frames = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    for v in m:\n",
    "        means.append(np.mean(v))\n",
    "        stds.append(np.std(v))\n",
    "        frames.append((v - np.mean(v)) / max(np.std(v), epsilon))\n",
    "    return np.array(frames), np.array(means), np.array(stds)\n",
    "\n",
    "def denormalize_frames(m, means, stds, epsilon=1e-12):\n",
    "    return np.array([z * max(stds[i],epsilon) + means[i] for i, z in enumerate(m)])\n",
    "\n",
    "def rolling_window(a, window, step=1):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
    "\n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Invertion to Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_for_reconstruction(x, params):\n",
    "    frames = framesig(x, frame_len=params['frame_len'] * params['sample_rate'], frame_step=params['frame_step'] * params['sample_rate'], winfunc=np.hamming)\n",
    "    fft_norm = np.fft.fft(frames, n=params['num_fft'])\n",
    "    return fft_norm\n",
    "\n",
    "def istft_for_reconstruction(X, total_lenght,  params):\n",
    "    frames = np.fft.ifft(X, n=params['num_fft'])\n",
    "    x = deframesig(frames, total_lenght, frame_len=params['num_fft'], frame_step=params['frame_step']*params['sample_rate'], winfunc=np.hamming)\n",
    "    return x\n",
    "\n",
    "def reconstruct_signal_griffin_lim(total_lenght, fft, params, iterations):\n",
    "    x_reconstruct = np.random.randn(total_lenght)\n",
    "    n = iterations\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "        reconstruction_spectrogram = stft_for_reconstruction(x_reconstruct, params)\n",
    "        reconstruction_angle = np.angle(reconstruction_spectrogram)\n",
    "        proposal_spectrogram = fft * np.exp(1.0j * reconstruction_angle)\n",
    "        prev_x = x_reconstruct\n",
    "        x_reconstruct = istft_for_reconstruction(proposal_spectrogram, total_lenght, params)\n",
    "        diff = np.sqrt(np.sum((fft - abs(proposal_spectrogram))**2)/fft.size)\n",
    "        print('\\rReconstruction iteration: {}/{} RMSE: {} '.format(iterations - n, iterations, diff), end='')\n",
    "    return x_reconstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set the path for the resulting master voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction iteration: 300/300 RMSE: 1.2251139773251946e-17 "
     ]
    }
   ],
   "source": [
    "master_voice_path = 'master_voice.wav'\n",
    "iterations_griffin_lim = 300\n",
    "starting_waveform, starting_rate = librosa.load(starting_path, sr=acoustic_params['sample_rate'], mono=True)\n",
    "denormalized_starting_spectrogram = denormalize_frames(starting_spectrogram, starting_waveform_mean, starting_waveform_std)\n",
    "x_reconstruct = reconstruct_signal_griffin_lim(len(starting_waveform), denormalized_starting_spectrogram.T, acoustic_params, iterations=iterations_griffin_lim)\n",
    "sf.write(master_voice_path, x_reconstruct, acoustic_params['sample_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Voice FAC 2462"
     ]
    }
   ],
   "source": [
    "starting_voice_spectrogram, starting_voice_mean, starting_voice_std = get_fft_spectrum(starting_path, acoustic_params)\n",
    "fac = evaluate_fac(starting_voice_spectrogram, bottleneck_extractor, utterance_paths, utterance_bottleneck_features, threshold=0.53)\n",
    "print('Starting Voice FAC', fac, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Voice FAC 6364"
     ]
    }
   ],
   "source": [
    "master_voice_spectrogram, master_voice_mean, master_voice_std = get_fft_spectrum(master_voice_path, acoustic_params)\n",
    "fac = evaluate_fac(master_voice_spectrogram, bottleneck_extractor, utterance_paths, utterance_bottleneck_features, threshold=0.53)\n",
    "print('Master Voice FAC', fac, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please find your Master Voice at master_voice.wav\n"
     ]
    }
   ],
   "source": [
    "print('Please find your Master Voice at', master_voice_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
