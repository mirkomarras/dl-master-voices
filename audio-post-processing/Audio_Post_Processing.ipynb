{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass to filter the noise (for Numpy)\n",
    "nyq = 0.5 * 16000\n",
    "low_value = 1000\n",
    "high_value = 7000\n",
    "low_cutoff = low_value / nyq\n",
    "high_cutoff = high_value / nyq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import IRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Mic IR\n",
    "1. IR_Crystal.wav\n",
    "2. IR_Lomo52A5M.wav\n",
    "3. IR_OktavaMD57.wav\n",
    "4. IR_AKGD12.wav\n",
    "5. IR_GaumontKalee.wav\n",
    "6. IR_STC4035.wav\n",
    "7. IR_MelodiumRM6.wav\n",
    "\n",
    "List of Speaker IR\n",
    "1. IR_ClestionBD300.wav\n",
    "2. IR_CelestionV30E606.wav\n",
    "3. IR_JensenCab.wav\n",
    "4. IR_Unknown.wav\n",
    "\n",
    "List of Room IR\n",
    "1. Room_01.wav\n",
    "2. Room_02.wav\n",
    "3. Room_03.wav\n",
    "4. Room_04.wav\n",
    "5. Room_05.wav\n",
    "6. Room_06.wav\n",
    "7. Room_07.wav\n",
    "8. Room_08.wav\n",
    "9. Room_09.wav\n",
    "\n",
    "***Note:*** Reset path to IRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker IR\n",
    "ir_speaker_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_speaker/IR_ClestionBD300.wav'\n",
    "ir_speaker, fs_speaker = librosa.load(ir_speaker_dir, sr=16000, mono=True)\n",
    "\n",
    "# Microphone IR\n",
    "ir_mic_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_mic/IR_GaumontKalee.wav'\n",
    "ir_mic, fs_mic = librosa.load(ir_mic_dir, sr=16000, mono=True)\n",
    "\n",
    "# Room IR\n",
    "ir_room_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_room/Room_01.wav'\n",
    "ir_room, fs_room = librosa.load(ir_room_dir, sr=16000, mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing function (Tensorflow)\n",
    "##### Input: Audio tensor (input)\n",
    "##### Output: Processed audio tensor (audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_post_processing(input_file):\n",
    "    \n",
    "    with tf.name_scope(\"audio_post_processing\") as scope:\n",
    "        \n",
    "        # ------- Speaker IR Convolution -------\n",
    "            \n",
    "        # Convolve with Speaker IR\n",
    "        ir_speaker_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Speaker_Tensor\")\n",
    "        ir_speaker_tensor = tf.expand_dims(ir_speaker_tensor, 1)\n",
    "        ir_speaker_tensor = tf.expand_dims(ir_speaker_tensor, 2)\n",
    "        \n",
    "        # Zero pad with speaker IR shape\n",
    "        pad_len_speaker = int(len(ir_speaker)/2 -1)\n",
    "        pad_speaker_value = tf.constant([[0,0], [pad_len_speaker,pad_len_speaker+1], [0,0]], name=\"Speaker_Pad\")\n",
    "        input_file = tf.pad(input_file, pad_speaker_value, \"CONSTANT\")\n",
    "\n",
    "        speaker_out = tf.nn.conv1d(input_file, ir_speaker_tensor, 1, padding=\"VALID\", name=\"Speaker_Out\")\n",
    "        \n",
    "        # ------- Noise Parameter -------\n",
    "        \n",
    "        # Add noise\n",
    "        s = speaker_out.get_shape().as_list()\n",
    "        noise_tensor = tf.random.normal([1,65536,1], mean=0, stddev=5e-3, dtype=tf.float32, name=\"Noise_param\")\n",
    "        \n",
    "        # ** Add filter **\n",
    "        \n",
    "        speaker_out = tf.add(speaker_out, noise_tensor, name=\"Speaker_plus_Noise\")\n",
    "\n",
    "        # ------- Room IR Convolution -------\n",
    "        \n",
    "        # Convolve with Room IR\n",
    "        ir_room_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Room_Tensor\")\n",
    "        ir_room_tensor = tf.expand_dims(ir_room_tensor, 1)\n",
    "        ir_room_tensor = tf.expand_dims(ir_room_tensor, 2)\n",
    "        \n",
    "        # Zero pad with Room IR shape\n",
    "        pad_len_room = int(len(ir_room)/2 -1)\n",
    "        pad_room_value = tf.constant([[0,0], [pad_len_room,pad_len_room+1], [0,0]])\n",
    "        speaker_out = tf.pad(speaker_out, pad_room_value, \"CONSTANT\", name=\"Room_Pad\")\n",
    "        \n",
    "        room_out = tf.nn.conv1d(speaker_out, ir_room_tensor, 1, padding=\"VALID\", name=\"Room_Out\")\n",
    "\n",
    "        # ------- Mic IR Convolution -------\n",
    "        \n",
    "        # Convolve with Mic IR\n",
    "        ir_mic_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Mic_Tensor\")\n",
    "        ir_mic_tensor = tf.expand_dims(ir_mic_tensor, 1)\n",
    "        ir_mic_tensor = tf.expand_dims(ir_mic_tensor, 2)\n",
    "        \n",
    "        # Zero pad with Mic IR shape\n",
    "        pad_len_mic = int(len(ir_mic)/2 -1)\n",
    "        pad_mic_value = tf.constant([[0,0], [pad_len_mic,pad_len_mic+1], [0,0]], name=\"Mic_Pad\")\n",
    "        room_out = tf.pad(room_out, pad_mic_value, \"CONSTANT\")\n",
    "        \n",
    "        audio_out = tf.nn.conv1d(room_out, ir_mic_tensor, 1, padding=\"VALID\", name=\"Audio_Out\")\n",
    "\n",
    "        return audio_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing function (Numpy)\n",
    "##### Input: Audio array (input)\n",
    "##### Output: Processed audio array (audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_post_processing(input_file):\n",
    "\n",
    "    # ------- Speaker IR Convolution -------\n",
    "    \n",
    "    # Zero pad with speaker IR shape\n",
    "    pad_speaker = np.zeros(ir_speaker.shape)\n",
    "    pad_len_speaker = int(len(pad_speaker)/2 -1)\n",
    "    speaker_pad = pad_speaker[:pad_len_speaker]\n",
    "\n",
    "    # Convolve with Speaker IR\n",
    "    input_file = np.concatenate((pad_speaker[:pad_len_speaker+1],\n",
    "                                 input_file,\n",
    "                                 pad_speaker[:pad_len_speaker]))\n",
    "    speaker_out = np.convolve(input_file, ir_speaker, mode='valid')\n",
    "\n",
    "    # ------- Noise Parameter -------\n",
    "\n",
    "    # Add noise\n",
    "    noise_param = np.random.normal(0, 5e-3, size=speaker_out.shape)\n",
    "\n",
    "    b, a = signal.cheby1(15, 4, [low_cutoff, high_cutoff], btype='bandpass')\n",
    "    noise_param = signal.filtfilt(b, a, noise_param)\n",
    "\n",
    "    speaker_out += noise_param\n",
    "\n",
    "    # ------- Room IR Convolution -------\n",
    "\n",
    "    # Zero pad with room IR shape\n",
    "    pad_room = np.zeros(ir_room.shape)\n",
    "    pad_len_room = int(len(pad_room)/2 -1)\n",
    "    room_pad = pad_room[:pad_len_room]\n",
    "\n",
    "    # Convolve with Room IR\n",
    "    speaker_out = np.concatenate((pad_room[:pad_len_room+1],\n",
    "                                  speaker_out,\n",
    "                                  pad_room[:pad_len_room]))\n",
    "    room_out = np.convolve(speaker_out, ir_room, mode='valid')\n",
    "\n",
    "    # ------- Mic IR Convolution -------\n",
    "\n",
    "    # Zero pad with mic IR shape\n",
    "    pad_mic = np.zeros(ir_mic.shape)\n",
    "    pad_len_mic = int(len(pad_mic)/2 -1)\n",
    "    mic_pad = pad_room[:pad_len_mic]\n",
    "\n",
    "    # Convolve with Mic IR\n",
    "    room_out = np.concatenate((pad_room[:pad_len_mic+1],\n",
    "                               room_out,\n",
    "                               pad_room[:pad_len_mic]))\n",
    "    audio_out = np.convolve(room_out, ir_mic, mode='valid')\n",
    "\n",
    "    return audio_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
