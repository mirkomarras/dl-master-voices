{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Post Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass to filter the noise\n",
    "nyq = 0.5 * 16000\n",
    "low_value = 1000\n",
    "high_value = 7000\n",
    "low_cutoff = low_value / nyq\n",
    "high_cutoff = high_value / nyq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import IRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** Reset path to IRs\n",
    "\n",
    "List of Mic IR\n",
    "1. IR_Crystal.wav\n",
    "2. IR_Lomo52A5M.wav\n",
    "3. IR_OktavaMD57.wav\n",
    "4. IR_AKGD12.wav\n",
    "5. IR_GaumontKalee.wav\n",
    "6. IR_STC4035.wav\n",
    "7. IR_MelodiumRM6.wav\n",
    "\n",
    "List of Speaker IR\n",
    "1. IR_ClestionBD300.wav\n",
    "2. IR_CelestionV30E606.wav\n",
    "3. IR_JensenCab.wav\n",
    "4. IR_Unknown.wav\n",
    "\n",
    "List of Room IR\n",
    "1. BRIR.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker IR\n",
    "ir_speaker_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_speaker/IR_ClestionBD300.wav'\n",
    "ir_speaker, fs_speaker = librosa.load(ir_speaker_dir, sr=16000, mono=True)\n",
    "\n",
    "# Microphone IR\n",
    "ir_mic_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_mic/IR_GaumontKalee.wav'\n",
    "ir_mic, fs_mic = librosa.load(ir_mic_dir, sr=16000, mono=True)\n",
    "\n",
    "# Room IR\n",
    "ir_room_dir = '/beegfs/kp2218/test_runs/conv_test/data/audio/ir_room/BRIR.wav'\n",
    "ir_room, fs_room = librosa.load(ir_room_dir, sr=16000, mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing function (Tensorflow)\n",
    "##### Input: Audio tensor (input)\n",
    "##### Output: Processed audio tensor (audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_post_processing(input_file):\n",
    "    \n",
    "    with tf.name_scope(\"post_processing\") as scope:\n",
    "        \n",
    "        # Convolve with Speaker IR\n",
    "        ir_speaker_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Speaker_Tensor\")\n",
    "        ir_speaker_tensor = tf.expand_dims(ir_speaker_tensor, 1)\n",
    "        ir_speaker_tensor = tf.expand_dims(ir_speaker_tensor, 2)\n",
    "        speaker_out = tf.nn.conv1d(input_file, ir_speaker_tensor, 1, padding=\"SAME\", name=\"Speaker_Out\")\n",
    "        \n",
    "        # Add noise\n",
    "        s = speaker_out.get_shape().as_list()\n",
    "        noise_tensor = tf.random.normal([1,65536,1], mean=0, stddev=5e-3, dtype=tf.float32, name=\"Noise_param\")\n",
    "        \n",
    "        # ** Add filter **\n",
    "        \n",
    "        speaker_out = tf.add(speaker_out, noise_tensor, name=\"Speaker_plus_Noise\")\n",
    "\n",
    "        # Convolve with Room IR\n",
    "        ir_room_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Room_Tensor\")\n",
    "        ir_room_tensor = tf.expand_dims(ir_room_tensor, 1)\n",
    "        ir_room_tensor = tf.expand_dims(ir_room_tensor, 2)\n",
    "        room_out = tf.nn.conv1d(speaker_out, ir_room_tensor, 1, padding=\"SAME\", name=\"Room_Out\")\n",
    "\n",
    "        # Convolve with Mic IR\n",
    "        ir_mic_tensor = tf.placeholder(dtype=tf.float32, shape=[None], name=\"Mic_Tensor\")\n",
    "        ir_mic_tensor = tf.expand_dims(ir_mic_tensor, 1)\n",
    "        ir_mic_tensor = tf.expand_dims(ir_mic_tensor, 2)\n",
    "        audio_out = tf.nn.conv1d(room_out, ir_mic_tensor, 1, padding=\"SAME\", name=\"Audio_Out\")\n",
    "\n",
    "        return audio_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing function (Numpy)\n",
    "##### Input: Audio array (input)\n",
    "##### Output: Processed audio array (audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_post_processing(input_file):\n",
    "\n",
    "    # Convolve with Speaker IR\n",
    "    speaker_out = np.convolve(input_file, ir_speaker, mode='same')\n",
    "\n",
    "    # Add noise\n",
    "    noise_param = np.random.normal(0, 5e-3, size=speaker_out.shape)\n",
    "\n",
    "    b, a = signal.cheby1(15, 4, [low_cutoff, high_cutoff], btype='bandpass')\n",
    "    noise_param = signal.filtfilt(b, a, noise_param)\n",
    "\n",
    "    speaker_out += noise_param\n",
    "\n",
    "    # Convolve with Room IR\n",
    "    room_out = np.convolve(speaker_out, ir_room, mode='same')\n",
    "\n",
    "    # Convolve with Mic IR\n",
    "    audio_out = np.convolve(room_out, ir_mic, mode='same')\n",
    "\n",
    "    return audio_out"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
